import streamlit as st
import os
from dotenv import load_dotenv
from langchain.chains.retrieval_qa.base import RetrievalQA
from prompt import prompts
from models import Models

# ğŸ”¹ Carregar variÃ¡veis do arquivo .env
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Gerador de Postagens para LinkedIn",
    page_icon="ğŸ’¼",
    layout="wide"
)

st.title("ğŸ’¼ Gerador de Postagens para LinkedIn")
st.markdown("---")

# ğŸ”¹ Sidebar para configuraÃ§Ãµes
with st.sidebar:
    st.header("ConfiguraÃ§Ãµes")
    
    # ğŸ”¹ Exibir API Key carregada (mas oculta para seguranÃ§a)
    if api_key:
        st.success("ğŸ”‘ API Key carregada do .env")
    else:
        st.error("âš ï¸ API Key nÃ£o encontrada no .env! Verifique o arquivo.")

    # SeleÃ§Ã£o do tipo de conteÃºdo
    content_type = st.selectbox("Tipo de GeraÃ§Ã£o", ["Conteudo", "Post", "Humanizar"])
    generate_image_option = st.checkbox("Gerar imagem do conteÃºdo com DALL-E")

# ğŸ”¹ Entrada do usuÃ¡rio (sempre visÃ­vel)
user_prompt = st.text_area("Digite o tema da postagem:", height=150)

# ğŸ”¹ BotÃ£o de gerar postagem
if st.button("Gerar Postagem"):
    if not api_key:
        st.error("âš ï¸ API Key nÃ£o foi encontrada! Verifique o arquivo .env.")
    elif not user_prompt.strip():
        st.warning("âš ï¸ Por favor, digite um tema para a postagem.")
    else:
        with st.spinner("Gerando postagem..."):
            try:
                model = Models()
                chat, vectordb = model.initialize_models(api_key)

                if not chat or not vectordb:
                    st.error("Erro ao inicializar modelos. Verifique sua OpenAI API Key.")
                else:
                    chain = RetrievalQA.from_chain_type(
                        llm=chat,
                        retriever=vectordb.as_retriever(
                            search_type='mmr',
                            search_kwargs={'k': 10, 'fetch_k': 20, 'lambda_mult': 0.7}
                        ),
                        chain_type_kwargs={'prompt': prompts[content_type]},
                        return_source_documents=True
                    )

                    response = chain.invoke({'query': user_prompt})

                    st.subheader("ğŸ“„ Postagem Gerada:")
                    st.write(response['result'])

                    st.download_button(
                        label="ğŸ“¥ Exportar Postagem",
                        data=response['result'],
                        file_name="postagem_linkedin.txt",
                        mime="text/plain"
                    )

                    if generate_image_option:
                        with st.spinner("Gerando imagem..."):
                            try:
                                dalle_prompt = f"Uma ilustraÃ§Ã£o profissional e moderna, sem texto: {response['result'][:500]}"
                                image_url = model.generate_image(dalle_prompt, api_key)
                                st.image(image_url, caption="Imagem gerada por DALL-E")
                            except Exception as e:
                                st.error(f"Erro ao gerar imagem: {str(e)}")

                    with st.expander("ğŸ“š Fontes consultadas"):
                        for i, doc in enumerate(response['source_documents'], 1):
                            st.markdown(f"**Fonte {i}:**")
                            st.text(doc.page_content[:200] + "...")

            except Exception as e:
                st.error(f"Erro ao gerar conteÃºdo: {str(e)}")
